---
title: "Applied Statistical Programming - dplyr and tidyr"
date: "3/2/2022"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{geometry}
   - \usepackage{hyperref}
   - \usepackage{setspace}
   - \usepackage{hyperref}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\textbf{Write the R code to answer the following questions. Write the code, and then show what the computer returns when that code is run. Thoroughly comment your solutions.}

You have until the beginning of class 3/7 at 10:00am to complete the assignment below. You may use R, but not any online R documentation. Submit the Rmarkdown and the knitted PDF to Canvas. Have one group member submit the activity with all group members listed at the top.

\section*{\texttt{dplyr} \& \texttt{tidyr}}

You've been hired by a campaign to do some data analysis during the primary stage of an election. Before you can start, you need to organize their data that they've provided. Your regressions need to be oriented towards candidate-state pairs for an eventual analysis of expected vote shares under different general election scenarios.

You used this same data for the previous in class activity. Your task is to re-organize the \texttt{primaryPolls} data so that there is only one row for each candidate-state dyad. Limit the data down to only the relevant candidates. Once complete, compare the size of this dataset to the original dataset using the \texttt{object\_size} command.

```{r eval=FALSE}
# Remove eval=FALSE to have this code block run.

# Load library dependencies
library(dplyr)
library(tidyr)
library(readr)

# Define path to the data
#dataURL <- 'https://jmontgomery.github.io/PDS/Datasets/president_primary_polls_feb2020.csv'
# Load the data
# NOTE: doing this locally
primaryPolls <- read.csv("president_primary_polls_feb2020.csv")
# Format the date
primaryPolls$start_date<-as.Date(primaryPolls$start_date, "%m/%d/%y")

# Your commented solution goes here.
max(primaryPolls$start_date)

newData <- primaryPolls %>%
  filter(start_date > "2019-12-08") %>% # the last two months
  group_by(pct, state, candidate_name) %>% # our selection of things we care about
  mutate(in_favor = pct/100) %>% # the proportion of supporters
  summarise(median_support = median(in_favor)) %>% 
  top_n(median_support, n = 10)


# Stuff I was doing on the side -- this also completes the second half of the assignment
dat <- primaryPolls %>%
  group_by(candidate_name, state, party) %>% # grouping by candidate, state, and party
  filter(state != "") %>% # dropping observations without a state
  summarise(mean_pct = mean(pct)) %>% # outputting the mean pct for each candidate, by state
  filter(mean_pct > 0) # getting rid of observations with percents = 0

head(dat)

object.size(dat)
object.size(primaryPolls)

# and messing around with `usmap`
library(usmap)
statemaps <- us_map(regions = "state")
statemaps$state <- statemaps$full

states <- inner_join(statemaps, dat, by = "state")

library(ggplot2)
map <- ggplot() +
  geom_polygon(data = states[states$candidate_name == "Joseph R. Biden Jr.",],
               aes(x = x, y = y, group = group, fill = mean_pct)) +
  labs(fill = "Percent Support") +
  scale_fill_continuous(low = "light blue", high = "dark blue", limits = c(0,100))+
  geom_polygon(data = statemaps, aes(x = x, y = y, group = group),
               fill = NA, col = "black") +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

map
```
